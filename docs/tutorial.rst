Tutorial
========

Accessing an existing array
---------------------------

Darr arrays are intended to be widely readable without Darr or Python, but the
easiest is simply to use Darr if that is available. On-disk data is
memory-mapped (i.e. not loaded in RAM), default is to access arrays in
read-only mode.

.. code:: python

    >>> import darr as da
    >>> a = da.Array('data.da')
    >>> a
    >>> array([[1., 2., 3., ..., 97., 98., 99.],
               [0., 0., 0., ..., 0., 0., 0.]]) (r)

If you intend to overwrite (part of) the data or append data (see below how)
you need to specify that and set 'accesmode' to 'r+'.

.. code:: python

    >>> import darr as da
    >>> a = da.Array('data.da', accessmode='r+')
    >>> a
    >>> array([[1., 2., 3., ..., 97., 98., 99.],
               [0., 0., 0., ..., 0., 0., 0.]]) (r+)

Creating an array
-----------------

.. code:: python

    >>> import darr as da
    >>> a = da.create_array('a1.da', shape=(2,1024))
    >>> a
    >>> array([[0., 0., 0., ..., 0., 0., 0.],
               [0., 0., 0., ..., 0., 0., 0.]]) (r+)

The default is to fill the array with zeros (of type float64) but this
can be changed by the 'fill' and 'fillfunc' parameters. See the api.

The data is now stored on disk in a directory named 'ar1.da', containing
a flat binary file ('arrayvalues.bin') and a human-readble
`JSON <https://en.wikipedia.org/wiki/JSON>`__ text file
('arraydescription.json'), with information on the array dimensionality,
layout and numeric type. It also contains a 'README.txt' file explaining
the data format as well as providing instructions on how to read the
array using other tools. For example, it provides the code to read the
array in `Octave <https://www.gnu.org/software/octave/>`__/Matlab:

.. code:: octave

    fileid = fopen('arrayvalues.bin');
    a = fread(fileid, [1024, 2], '*float64', 'ieee-le');
    fclose(fileid);

Or in `R <https://cran.r-project.org/>`__:

.. code:: R

    fileid = file("arrayvalues.bin", "rb")
    a = readBin(con=fileid, what=numeric(), n=2048, size=8, endian="little")
    a = array(data=a, dim=c(1024, 2), dimnames=NULL)
    close(fileid)

Or in `Julia <https://julialang.org/>`__:

.. code:: julia

    fid = open("arrayvalues.bin","r");
    x = map(ltoh, read(fid, Float64, (1024, 2)));
    close(fid);

To see the files that correspond to a Darr array, see
'examplearray.da' in the source
`repo <https://github.com/gbeckers/Darr>`__.

Different numeric type
----------------------

.. code:: python

    >>> a = da.create_array('a2.da', shape=(2,1024), dtype='uint8')
    >>> a
    array([[0, 0, 0, ..., 0, 0, 0],
           [0, 0, 0, ..., 0, 0, 0]], dtype=uint8) (r+)

Creating array from NumPy array
-------------------------------

.. code:: python

    >>> import numpy as np
    >>> na = np.ones((2,1024))
    >>> a = da.asarray('a3.da', na)
    >>> a
    array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],
           [ 1.,  1.,  1., ...,  1.,  1.,  1.]]) (r)

Reading data
------------

The disk-based array is memory-mapped and can be used to read data into
RAM using NumPy indexing.

.. code:: python

    >>> a[:,-2]
    array([ 1.,  1.])

Note that that creates a NumPy array. The darr array itself is not a NumPy
array, nor does it behave like one except for indexing. The simplest way
to use the data for computation is to, read (or view, see below) the
data first as a NumPy array:

.. code:: python

    >>> 2 * a[:]
    array([[2., 2., 2., ..., 2., 2., 2.],
           [2., 2., 2., ..., 2., 2., 2.]])

If your data is too large to read into RAM, you could use the
`Dask <https://dask.pydata.org/en/latest/>`__ or the
`NumExpr <https://numexpr.readthedocs.io/en/latest/>`__ library for
computation (see example below).

Writing data
------------

Writing is also done through NumPy indexing. Writing directly leads to
changes on disk. Our example array is read-only because we did not
specify otherwise in the 'asarray' function above, so we'll set it to
be writable first:

.. code:: python

    >>> a.set_accessmode('r+')
    >>> a[:,1] = 2.
    >>> a
    array([[ 1.,  2.,  1., ...,  1.,  1.,  1.],
           [ 1.,  2.,  1., ...,  1.,  1.,  1.]]) (r+)

Efficient I/O
-------------

To get maximum speed when doing multiple operations, open a direct view
on the disk-based array so as to open and close the underlying files only once:

.. code:: python

    >>> with a.view() as v:
    ...     v[0,0] = 3.
    ...     v[0,2] = 4.
    ...     v[1,[0,2,-1]] = 5.
    >>> a
    array([[ 3.,  2.,  4., ...,  1.,  1.,  1.],
          [ 5.,  2.,  5., ...,  1.,  1.,  5.]]) (r+)

Appending data
--------------

You can easily append data to a Darr array, which is immediately reflected
in the disk-based files. This is a big plus in many situations. Think
for example of saving data as they are generated by an instrument. A
restriction is that you can only append to the first axis:

.. code:: python

    >>> a.append(np.ones((3,1024)))
    >>> a
    array([[3., 2., 4., ..., 1., 1., 1.],
           [5., 2., 5., ..., 1., 1., 5.],
           [1., 1., 1., ..., 1., 1., 1.],
           [1., 1., 1., ..., 1., 1., 1.],
           [1., 1., 1., ..., 1., 1., 1.]]) (r+)

The associated 'README.txt' and 'arraydescription.json' texts files are
also automatically updated to reflect these changes. There is an
'iterappend' method for efficient serial appending. See the api.

Copying and type casting data
-----------------------------

.. code:: python

    >>> ac = a.copy('ac.da')
    >>> acf16 = a.copy('acf16.da', dtype='float16')
    >>> acf16
    array([[3., 2., 4., ..., 1., 1., 1.],
           [5., 2., 5., ..., 1., 1., 5.],
           [1., 1., 1., ..., 1., 1., 1.],
           [1., 1., 1., ..., 1., 1., 1.],
           [1., 1., 1., ..., 1., 1., 1.]], dtype=float16) (r)

Note that the type of the array can be changed when copying. Data is
copied in chunks, so very large arrays will not flood RAM memory.

Larger than memory computation
------------------------------

For computing with very large darr arrays, I recommend the
`Dask <https://dask.pydata.org/en/latest/>`__ library, which works
nicely with darr. I'll base the example on a small array though:

.. code:: python

    >>> import dask.array
    >>> a = da.create_array('ar1.da', shape=(1024**2), fill=2.5, overwrite=True)
    >>> a
    array([2.5, 2.5, 2.5, ..., 2.5, 2.5, 2.5]) (r+)
    >>> dara = dask.array.from_array(a, chunks=(512))
    >>> ((dara + 1) / 2).store(a)
    >>> a
    array([1.75, 1.75, 1.75, ..., 1.75, 1.75, 1.75]) (r+)

So in this case we overwrote the data in a with the results of the
computation, but we could have stored the result in a different darr array
of the same shape. Dask can do more powerful things, for which I refer
to the `Dask
documentation <https://dask.pydata.org/en/latest/index.html>`__. The
point here is that darr arrays can be both sources and stores for Dask.

Alternatively, you can use the
`NumExpr <https://numexpr.readthedocs.io/en/latest/>`__ library using a
view of the Darr array, like so:

.. code:: python

    >>> import numexpr as ne
    >>> a = da.create_array('a3.da', shape=(1024**2), fill=2.5)
    >>> with a.view() as v:
    ...     ne.evaluate('(v + 1) / 2', out=v)
    >>> a
    array([1.75, 1.75, 1.75, ..., 1.75, 1.75, 1.75]) (r+)

Metadata
--------

Metadata can be read and written like a dictionary. Changes correspond
to changes in a human-readable and editable JSON text file that holds
the metadata on disk.

.. code:: python

    >>> a.metadata
    {}
    >>> a.metadata['samplingrate'] = 1000.
    >>> a.metadata
    {'samplingrate': 1000.0}
    >>> a.metadata.update({'starttime': '12:00:00', 'electrodes': [2, 5]})
    >>> a.metadata
    {'electrodes': [2, 5], 'samplingrate': 1000.0, 'starttime': '12:00:00'}
    >>> a.metadata['starttime'] = '13:00:00'
    >>> a.metadata
    {'electrodes': [2, 5], 'samplingrate': 1000.0, 'starttime': '13:00:00'}
    >>> del a.metadata['starttime']
    a.metadata
    {'electrodes': [2, 5], 'samplingrate': 1000.0}

Since JSON is used to store the metadata, you cannot store arbitrary
python objects. You can only store:

-  strings
-  numbers
-  booleans (True/False)
-  None
-  lists
-  dictionaries with string keys

